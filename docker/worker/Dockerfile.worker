# Cloud Run Job Dockerfile for GPU training worker
# Based on NVIDIA's PyTorch container with CUDA support
# Aligned with existing LaxAI Dockerfile patterns

ARG BASE_IMAGE=pytorch/pytorch:2.8.0-cuda12.8-cudnn9-runtime
ARG DEPS_IMAGE=fmousinho/laxai-deps:latest
ARG GOOGLE_CLOUD_PROJECT=""
ARG ENTRY_POINT="python src/cloud/worker.py"

FROM ${DEPS_IMAGE} AS deps

FROM ${BASE_IMAGE}

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT}
ENV ENTRY_POINT=${ENTRY_POINT}
ENV TRAINING_JOBS_SUBSCRIPTION="training-jobs-sub"
ENV FIRESTORE_ENABLED="true"
ENV WORKER_TIMEOUT="3600"
ENV MAX_CONCURRENT_JOBS="1"

WORKDIR /app

# Copy prebuilt wheels and requirements
COPY --from=deps /wheels /wheels
ARG REQS=requirements-gpu.txt
COPY requirements/ requirements/

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3-pip \
    git \
    wget \
    curl \
    unzip \
    libglib2.0-0 \
    libsm6 \
    libxrender1 \
    libxext6 \
    libgl1 \
    && rm -rf /var/lib/apt/lists/*

# Strict: only install from /wheels, fail if not present
RUN test -d /wheels && test "$(ls -A /wheels)" \
    && pip install --no-cache-dir --find-links /wheels -r requirements/${REQS}

# Copy source code
COPY documentation /app/documentation
COPY config.toml /app/
COPY pyproject.toml .
COPY README.md .
COPY src/config/gcs_structure.yaml /app/src/config/gcs_structure.yaml


RUN mkdir -p /tmp/models /tmp/artifacts

CMD ["sh", "-c", "exec $ENTRY_POINT"]