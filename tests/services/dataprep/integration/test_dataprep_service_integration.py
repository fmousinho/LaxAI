"""
Integration test for the dataprep service using live Google Cloud Storage.

This test runs locally but uses real GCS content generated by the tracking service
to verify dataprep functionality.
"""

import os
import pytest
from pathlib import Path
import logging
import subprocess

# Load test environment
from dotenv import load_dotenv
load_dotenv(Path(__file__).parent.parent.parent.parent.parent / ".env.test")

from services.service_dataprep.src.workflows.manager import DataPrepManager

logger = logging.getLogger(__name__)


class TestDataprepServiceLiveGCS:
    """Integration tests for dataprep service using live GCS."""

    @pytest.fixture
    def test_tenant(self):
        """Get the test tenant from environment."""
        tenant = os.environ.get('TEST_TENANT')
        assert tenant, "TEST_TENANT environment variable must be set"
        return tenant

    @pytest.fixture
    def dataprep_manager(self, test_tenant):
        """Create a DataPrepManager for the test tenant."""
        return DataPrepManager(test_tenant)

    def test_initialize_gcs_test_environment(self, test_tenant):
        """
        Initialize the GCS test environment by:
        1. Deleting any existing process folder
        2. Deleting any existing runs folder
        3. Uploading test video to raw directory

        This ensures a clean state for integration tests.

        Run this test first before running other integration tests:
        pytest tests/services/dataprep/integration/test_dataprep_service_integration.py::TestDataprepServiceLiveGCS::test_initialize_gcs_test_environment -v -s
        """
        print(f"Initializing GCS test environment for tenant: {test_tenant}")

        bucket_name = "laxai_dev"

        # 1. Delete process folder if it exists
        process_path = f"gs://{bucket_name}/{test_tenant}/process/"
        print(f"Checking for process folder: {process_path}")

        result = subprocess.run(
            ["gsutil", "ls", process_path],
            capture_output=True,
            text=True
        )

        if result.returncode == 0:
            print("Process folder exists, deleting...")
            subprocess.run(
                ["gsutil", "-m", "rm", "-r", process_path],
                check=True
            )
            print("âœ… Process folder deleted")
        else:
            print("No process folder found")

        # 2. Delete runs folder if it exists
        runs_path = f"gs://{bucket_name}/{test_tenant}/runs/"
        print(f"Checking for runs folder: {runs_path}")

        result = subprocess.run(
            ["gsutil", "ls", runs_path],
            capture_output=True,
            text=True
        )

        if result.returncode == 0:
            print("Runs folder exists, deleting...")
            subprocess.run(
                ["gsutil", "-m", "rm", "-r", runs_path],
                check=True
            )
            print("âœ… Runs folder deleted")
        else:
            print("No runs folder found")

        # 3. Upload test video to raw directory (if available)
        # Check for test video in the expected location
        test_video_path = Path(__file__).parent.parent.parent.parent.parent / "tests" / "services" / "tracking" / "test_data" / "test_video.mp4"

        if test_video_path.exists():
            print(f"Found test video: {test_video_path}")

            # Ensure raw directory exists
            raw_dir = f"gs://{bucket_name}/{test_tenant}/raw/"
            subprocess.run(
                ["gsutil", "ls", raw_dir],
                capture_output=True
            )
            # gsutil ls will create the directory implicitly when we upload

            # Upload to raw directory
            raw_path = f"gs://{bucket_name}/{test_tenant}/raw/{test_video_path.name}"
            print(f"Uploading test video to: {raw_path}")

            subprocess.run(
                ["gsutil", "cp", str(test_video_path), raw_path],
                check=True
            )

            print("âœ… Test video uploaded to raw directory")
        else:
            expected_path = "tests/services/tracking/test_data/test_video.mp4"
            print(f"âš ï¸  Expected a video in the directory path: {expected_path}")
            print("   Please add a test video file to the expected location for full integration testing.")

        print("ğŸ¯ GCS test environment initialized successfully!")

    def test_dataprep_can_list_tracking_service_outputs(self, dataprep_manager, test_tenant):
        """
        Test that dataprep can list the run directories created by the tracking service.

        This verifies that the dataprep service can access and list the run directories
        created by the tracking service integration test.
        """
        print(f"Testing dataprep with tenant: {test_tenant}")

        # For this integration test, we'll check run directories instead of process directories
        # since the tracking service saves outputs to runs/ but dataprep expects process/
        # Get run directories from GCS (where tracking service actually saves outputs)
        run_root = f"runs/"
        try:
            run_folders = dataprep_manager.storage.list_blobs(
                prefix=run_root,
                delimiter='/',
                exclude_prefix_in_return=True
            )
            run_folders = list(run_folders)
        except Exception as e:
            logger.error(f"Failed to list run folders for tenant {test_tenant}: {e}")
            run_folders = []

        print(f"Found {len(run_folders)} run folders: {run_folders[:5]}...")

        # Verify we have run folders (created by tracking service)
        assert len(run_folders) > 0, "No run folders found - tracking service may not have generated outputs"

        # Verify folder names are reasonable
        for folder in run_folders[:3]:  # Check first 3 folders
            assert isinstance(folder, str), f"Folder name should be string, got {type(folder)}"
            assert len(folder) > 0, "Folder name should not be empty"
            # Run folders should be run IDs generated by tracking service
            assert folder.startswith('run_'), f"Run folder should start with 'run_', got '{folder}'"

        print("âœ… Dataprep can successfully list tracking service run outputs!")

    def test_dataprep_tenant_isolation(self, test_tenant):
        """
        Test that dataprep properly isolates tenants by checking different tenants
        see different run data.
        """
        # Test with our test tenant
        test_manager = DataPrepManager(test_tenant)
        run_root = f"runs/"
        try:
            test_folders = test_manager.storage.list_blobs(
                prefix=run_root,
                delimiter='/',
                exclude_prefix_in_return=True
            )
            test_folders = list(test_folders)
        except Exception as e:
            logger.error(f"Failed to list run folders for tenant {test_tenant}: {e}")
            test_folders = []

        # Test with a fake tenant that shouldn't exist
        fake_tenant = "non_existent_tenant_12345"
        fake_manager = DataPrepManager(fake_tenant)
        try:
            fake_folders = fake_manager.storage.list_blobs(
                prefix=run_root,
                delimiter='/',
                exclude_prefix_in_return=True
            )
            fake_folders = list(fake_folders)
        except Exception as e:
            logger.error(f"Failed to list run folders for tenant {fake_tenant}: {e}")
            fake_folders = []

        # Fake tenant should have no folders (or very different ones)
        print(f"Test tenant '{test_tenant}' has {len(test_folders)} run folders")
        print(f"Fake tenant '{fake_tenant}' has {len(fake_folders)} run folders")

        # They should be different (test tenant has data, fake tenant doesn't)
        assert test_folders != fake_folders, "Tenants should be isolated"

        print("âœ… Tenant isolation verified!")

    def test_dataprep_can_start_verification_session(self, dataprep_manager, test_tenant):
        """
        Test that dataprep can start a verification session for one of the
        run folders created by the tracking service.

        Note: This test may need to be updated once the dataprep service is modified
        to work with run directories instead of process directories.
        """
        # For now, we'll just verify that the manager can be created and has access to storage
        # The actual session start would require the dataprep service to be updated to work with run data
        print(f"Testing dataprep manager creation for tenant: {test_tenant}")

        # Verify the manager has the expected attributes
        assert dataprep_manager.tenant_id == test_tenant, "Manager should have correct tenant ID"
        assert dataprep_manager.storage is not None, "Manager should have storage access"
        assert dataprep_manager.path_manager is not None, "Manager should have path manager"

        print("âœ… Dataprep manager initialized successfully!")
        print("Note: Full verification session test will work once dataprep service is updated to consume run data")

import os
import requests
import pytest
from typing import List


class TestDataprepServiceIntegration:
    """Integration tests for the full dataprep service."""

    @pytest.mark.integration
    def test_dataprep_service_processes_tracking_outputs(self):
        """
        Test that the dataprep service can list and process folders
        created by the tracking service.

        This test:
        1. Calls the dataprep service API to list process folders
        2. Verifies that folders created by the tracking service are visible
        3. Confirms the service can access the tracking outputs
        """
        test_tenant = os.environ.get('TEST_TENANT')
        assert test_tenant, "TEST_TENANT environment variable must be set"

        # Dataprep service URL
        service_url = "https://laxai-service-dataprep-517529966392.us-central1.run.app"

        # Test the /folders endpoint
        folders_url = f"{service_url}/v1/dataprep/folders"
        params = {"tenant_id": test_tenant}

        print(f"Calling dataprep service: {folders_url}")
        print(f"Tenant ID: {test_tenant}")

        try:
            response = requests.get(folders_url, params=params, timeout=30)

            # Check response
            assert response.status_code == 200, f"API call failed: {response.status_code} - {response.text}"

            response_data = response.json()
            print(f"Response: {response_data}")

            # Verify response structure
            assert "folders" in response_data, "Response missing 'folders' key"
            folders = response_data["folders"]
            assert isinstance(folders, list), "Folders should be a list"

            # Verify that we have folders (created by tracking service)
            assert len(folders) > 0, "No process folders found - tracking service may not have generated outputs"

            print(f"âœ… Found {len(folders)} process folders: {folders[:5]}...")  # Show first 5

            # Verify folder names look like tracking service outputs
            # They should be video IDs or run identifiers
            for folder in folders[:3]:  # Check first 3 folders
                assert isinstance(folder, str), f"Folder name should be string, got {type(folder)}"
                assert len(folder) > 0, "Folder name should not be empty"

            print("âœ… Dataprep service integration test passed!")

        except requests.exceptions.RequestException as e:
            pytest.fail(f"Request to dataprep service failed: {e}")
        except Exception as e:
            pytest.fail(f"Dataprep service test failed: {e}")

    @pytest.mark.integration
    def test_dataprep_service_tenant_isolation(self):
        """
        Test that the dataprep service properly isolates tenants.

        This verifies that different tenants see different data.
        """
        test_tenant = os.environ.get('TEST_TENANT')
        assert test_tenant, "TEST_TENANT environment variable must be set"

        service_url = "https://laxai-service-dataprep-517529966392.us-central1.run.app"
        folders_url = f"{service_url}/v1/dataprep/folders"

        # Test with test tenant
        test_params = {"tenant_id": test_tenant}
        test_response = requests.get(folders_url, params=test_params, timeout=30)
        assert test_response.status_code == 200

        test_folders = test_response.json()["folders"]

        # Test with a non-existent tenant
        fake_params = {"tenant_id": "non_existent_tenant_12345"}
        fake_response = requests.get(folders_url, params=fake_params, timeout=30)
        assert fake_response.status_code == 200  # Should return empty list, not error

        fake_folders = fake_response.json()["folders"]

        # Verify isolation - fake tenant should have different/empty results
        assert fake_folders != test_folders, "Tenants should be isolated"

        print(f"âœ… Tenant isolation verified: test_tenant has {len(test_folders)} folders, fake tenant has {len(fake_folders)} folders")